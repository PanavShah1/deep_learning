{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpRicanjpaFpSdNqjicnqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PanavShah1/deep_learning/blob/main/04_pytorch_custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. PyTorch Custom Datasets\n",
        "\n",
        "We've used some datasets with PyTorch before.\n",
        "\n",
        "But how do you get your own data into PyTorch.\n",
        "\n",
        "One of the ways to do so is via: custom datasets:\n",
        "\n",
        "## Domain libraries\n",
        "\n",
        "Depending on what you're working on, vision, test, ausio, recommendation, you'll want to look into each of the PyTorch domain libraries for existing data loading functions and customizable data loading functions"
      ],
      "metadata": {
        "id": "64--FUwmq2-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code"
      ],
      "metadata": {
        "id": "4lJwE3N2skP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k18LX1eYtLeb",
        "outputId": "135e6ccd-8d69-4782-8401-55a078891514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SGVW9HV5tPcy",
        "outputId": "c49b6333-666b-4b93-ceb8-f1223fb559db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D6FWio2tcBT",
        "outputId": "9b26ef43-612e-4556-b80a-21ee839b083f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "Our dataset is a subset of the Food101 dataset.\n",
        "\n",
        "Food101 starts 101 different classes of food and 1000 images per class (750 training, 250 testing)\n",
        "\n",
        "Our dataset starts with 3 classes of food and only 10% of the images(~75 training, 25 testing)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZcLrGSRItets"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to a data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exists... skipping download\")\n",
        "else:\n",
        "  print(f\"{image_path} does not exist... creating one\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Download pizza, steak and sushi data\n",
        "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip?raw=true\")\n",
        "    print(\"Downloading pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "  # Unzip pizza, steak, sushi data\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak and sushi data...\")\n",
        "    zip_ref.extractall(image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGYQPKVDtkni",
        "outputId": "d770c809-935b-4dae-ccc5-99c4ed3fa97e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory already exists... skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data preparation and data exploration"
      ],
      "metadata": {
        "id": "XJrG_MX0xVjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "26OlOGy9xZOY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}